# 环境变量释义

|变量名称|释义|示例|
|----|------------------|----|
|SGLANG_EXPERT_DISTRIBUTION_RECORD_DIR|`SGLANG_EXPERT_DISTRIBUTION_RECORD_DIR`环境变量主要用于指定**专家模型分布记录的存储目录**。<br>具体来说，它的作用包括：<br>1. 当使用SGLang的专家模型分布（expert distribution）功能时（例如在MoE架构或分布式推理场景中），该变量定义了记录专家分配、负载均衡或路由信息的文件存储路径。<br>2. 这些记录文件可用于调试分布式推理过程中的专家选择策略、性能分析或问题排查。<br>3. 若未指定该变量，SGLang可能会使用默认目录（通常是临时目录或当前工作目录）来存储这些记录文件。<br>通过设置该环境变量，用户可以灵活指定记录文件的存储位置，方便后续对分布式推理过程进行分析和优化。||
|GLOO_SOCKET_IFNAME|`GLOO_SOCKET_IFNAME`环境变量主要用于指定**GLOO通信库使用的网络接口名称**。<br>GLOO是Facebook开发的一个分布式通信库，常被用于深度学习框架（如PyTorch）和分布式计算场景中，负责节点间的数据传输和通信协调。在SGLang的分布式部署场景（如多节点推理、MoE架构的专家节点通信等）中，可能会依赖GLOO实现跨容器/跨节点的通信。<br>该环境变量的具体作用是：<br>1. 明确指定容器内用于GLOO通信的网络接口（如`eth0`、`enp0s3`等）<br>2. 避免在多网络接口的容器环境中，GLOO错误选择不合适的网络接口（如内网接口、管理接口等）<br>3. 优化分布式通信性能，确保使用预期的高性能网络链路。<br>如果不设置该变量，GLOO可能会自动选择一个网络接口，但在复杂网络环境（如容器多网卡、overlay网络等）中可能导致通信失败或性能下降。因此，在SGLang的分布式部署中，通常需要根据容器网络配置显式指定该变量。|bond0|
|MACA_SMALL_PAGESIZE_ENABLE|`MACA_SMALL_PAGESIZE_ENABLE`环境变量主要与**内存分配和页面管理优化**相关，具体作用如下：<br>该变量通常用于控制是否启用"小页面"（small page）内存分配模式。在高性能计算或大模型推理场景中，内存管理的效率对整体性能影响显著：<br>1. 当启用（设置为`1`或`true`）时，系统可能会使用更小的内存页面粒度进行分配，这有助于减少内存碎片，提高内存利用率，尤其适合处理大量小内存块的场景。<br>2. 当禁用（默认可能为`0`或`false`）时，可能使用默认的页面大小（通常较大，如4KB或更大），这在某些大内存连续分配场景中可能更高效。<br>这一配置通常与SGLang底层依赖的内存管理库（如MACA相关组件）配合工作，旨在根据具体 workload 特性优化内存使用效率，进而提升模型推理或计算性能。在容器环境中显式设置该变量，可以更精确地控制内存行为，适配不同的硬件资源和应用需求。|1|
|NVSHMEM_DISABLE_CUDA_VMM|`NVSHMEM_DISABLE_CUDA_VMM`环境变量与**NVIDIA SHMEM（NVSHMEM）库的CUDA虚拟内存管理（VMM）功能**相关，其主要作用是控制是否禁用CUDA VMM功能。<br>具体来说：<br>1. NVSHMEM是NVIDIA提供的分布式内存编程库，用于跨GPU或跨节点的高性能通信，在SGLang的多GPU分布式推理场景中可能被用于高效数据交换。<br>2. CUDA VMM（虚拟内存管理）是CUDA的一项功能，允许应用程序使用更大的虚拟地址空间，灵活管理GPU内存。<br>3. 当`NVSHMEM_DISABLE_CUDA_VMM`设置为`1`或`true`时，会禁用NVSHMEM对CUDA VMM的使用；默认情况下可能为`0`（启用状态）。<br>在实际场景中，禁用该功能可能是为了：<br>1. 解决特定环境下CUDA VMM与NVSHMEM兼容问题（如驱动版本不匹配、硬件限制等）。<br>2. 规避某些边缘场景下的内存管理性能问题或bug。<br>3. 适配需要使用传统内存管理模式的部署环境。<br>该变量通常仅在遇到NVSHMEM与CUDA VMM相关的兼容性问题时才需要显式设置，一般情况下保持默认值即可。|1|
|NVSHMEM_SYMMETRIC_SIZE|`NVSHMEM_SYMMETRIC_SIZE`环境变量用于配置**NVIDIA SHMEM（NVSHMEM）库的对称内存区域大小**。<br>具体作用如下：<br>1. NVSHMEM是NVIDIA针对GPU间通信设计的分布式内存库，其核心概念之一是"对称内存区域"（symmetric memory region）——这是一块在所有参与通信的GPU上具有相同地址和大小的内存区域，便于跨设备直接访问数据。<br>2. `NVSHMEM_SYMMETRIC_SIZE`用于指定该对称内存区域的总大小（通常以字节为单位），所有参与通信的GPU会分配相同大小的对称内存。<br>3. 在SGLang的多GPU分布式推理场景中（如MoE架构的专家并行、张量并行等），对称内存区域用于高效交换中间计算结果、模型参数分片等数据，减少跨GPU通信的开销。<br>若未显式设置，NVSHMEM可能会使用默认大小（通常取决于系统配置），但在大模型场景下，可能需要根据模型规模、通信需求手动调整该值，以避免内存不足或资源浪费。设置时需确保所有节点的配置一致，否则可能导致通信异常。|3g|
|TRITON_DISABLE_MACA_OPT_MMA_PREFETCH|`TRITON_DISABLE_MACA_OPT_MMA_PREFETCH`环境变量主要与**Triton编译器的MACA优化相关**，具体作用是控制是否禁用MACA（可能是指特定的内存访问或计算优化组件）中的MMA（矩阵乘法累加）预取优化。具体来说：<br>1. Triton是用于GPU编程的开源编译器，常用于优化深度学习中的张量运算（如矩阵乘法），在SGLang的模型推理过程中可能被用于加速底层计算。<br>2. MMA（Matrix Multiply-Accumulate）是GPU架构中用于高效执行矩阵乘法的核心指令，预取优化（prefetch）则是通过提前加载数据到缓存来减少内存访问延迟的技术。<br>3. 当该环境变量设置为`1`或`true`时，会禁用Triton编译器针对MMA操作的预取优化；默认情况下可能为`0`（启用状态）。<br>在实际场景中，禁用该优化可能是为了：<br>1. 解决特定硬件或软件版本下，预取优化导致的兼容性问题（如计算结果异常、程序崩溃等）。<br>2. 针对某些模型或计算场景，预取策略可能反而引入额外开销，此时禁用可提升性能。<br>3. 调试底层计算优化相关的问题，定位性能瓶颈或逻辑错误。<br>该变量通常仅在遇到与Triton编译器优化相关的问题时才需要显式设置，一般情况下保持默认值（启用优化）即可获得更好的计算效率。|1|
|TRITON_ENABLE_ELEMENTWISE_PK_FMA_OPT|`TRITON_ENABLE_ELEMENTWISE_PK_FMA_OPT`环境变量主要与**Triton编译器的元素级操作优化**相关，具体作用是控制是否启用针对“元素级操作+打包（packed）FMA（ fused multiply-add，融合乘加）”组合的特定优化。具体说明如下：<br>1. Triton编译器常用于优化GPU上的张量计算，而元素级操作（如逐元素加减乘除）与FMA指令的结合是深度学习计算中的常见模式（例如激活函数计算、残差连接等场景）。<br>2. “打包（packed）”优化通常指将多个操作数或计算步骤合并处理，以更高效地利用GPU的计算单元（如CUDA核心）。<br>3. FMA作为一种将乘法和加法融合为单条指令的操作，本身已具备较高效率，而该环境变量控制的优化则进一步针对元素级操作与FMA的组合场景，通过特定策略（如指令重排、数据布局调整等）减少计算延迟或提升并行效率。<br>当该变量设置为`1`或`true`时，会启用这项优化；默认可能为`0`（不启用）或根据编译配置自动决定。在实际使用中，启用该优化可能在特定模型（如包含大量元素级组合运算的网络）的推理场景中提升性能，但也可能因硬件架构或计算模式的差异，需要通过测试验证其效果。<br>通常情况下，该变量仅在需要针对性优化元素级与FMA组合操作的场景中显式设置，以适配特定模型或硬件环境。|True|
|TRITON_ENABLE_MACA_CHAIN_DOT_OPT|`TRITON_ENABLE_MACA_CHAIN_DOT_OPT`环境变量主要与**Triton编译器针对链式点积（chain dot）运算的优化**相关，具体作用如下：<br>该变量用于控制是否启用Triton编译器中针对“链式点积”操作的特定优化（MACA可能指代相关的内存访问或计算加速组件）。链式点积通常指由多个连续点积运算组成的计算模式，这类操作在Transformer等模型的注意力机制、特征交互等场景中较为常见。<br>启用该优化（设置为`1`或`true`）时，Triton编译器可能会：<br>1. 对连续的点积运算进行合并或重排，减少冗余计算。<br>2. 优化数据在GPU内存中的布局和访问模式，提升缓存利用率。<br>3. 更好地适配GPU硬件的计算单元（如Tensor Core），提高计算效率。<br>禁用时（默认可能为`0`），则不启用这些针对性优化，使用常规编译策略。<br>该变量的设置通常用于在特定模型或计算场景中进一步挖掘性能潜力，尤其适合包含大量连续点积操作的网络结构。但优化效果可能因具体计算模式和硬件架构而异，有时需要通过测试验证是否启用更优。|1|
|TRITON_ENABLE_MACA_COMPILER_INT8_OPT|`TRITON_ENABLE_MACA_COMPILER_INT8_OPT`环境变量主要与**Triton编译器针对INT8精度计算的优化**相关，具体作用如下：<br>该变量用于控制是否启用Triton编译器中与MACA组件（可能涉及内存访问、计算调度等底层优化模块）相关的INT8精度优化。INT8是一种低精度数据格式，在深度学习推理中常被用于在保证模型精度可接受的前提下，显著提升计算效率、降低内存带宽需求和减少能耗。<br>当启用该优化（设置为`1`或`true`）时，Triton编译器可能会：<br>1. 对INT8精度的张量运算（如矩阵乘法、卷积等）进行特定优化，更好地适配GPU硬件的INT8计算单元（如Tensor Core对低精度的支持）。<br>2. 优化INT8数据的内存布局和访问模式，减少类型转换开销。<br>3. 结合MACA组件的特性，提升INT8计算的并行效率和缓存利用率。<br>禁用时（默认可能为`0`），则不启用这些针对性的INT8优化，使用常规编译策略处理低精度计算。<br>该变量的设置通常用于在采用INT8量化推理的场景中进一步提升性能，尤其适合对计算效率要求较高的大模型部署场景。但优化效果可能因模型结构、量化策略和硬件架构而异，需要根据实际场景测试验证。|1|
|TRITON_ENABLE_MACA_OPT_MOVE_DOT_OPERANDS_OUT_LOOP|`TRITON_ENABLE_MACA_OPT_MOVE_DOT_OPERANDS_OUT_LOOP`环境变量主要与**Triton编译器的循环优化**相关，具体作用是控制是否启用将“点积（dot）操作数移出循环”的特定优化（MACA可能指代相关的内存访问或计算优化组件）。具体说明如下。<br>1. 在循环结构中（尤其是深度学习计算中常见的嵌套循环，如矩阵乘法的三重循环），点积操作的操作数（如参与运算的向量或张量片段）若被重复使用，将其从循环内部移至外部可以避免重复加载或计算，减少冗余的内存访问和数据处理开销。<br>2. 启用该优化（设置为`1`或`true`）时，Triton编译器会分析循环内的点积操作，将符合条件的操作数提升至循环外，仅进行一次加载或初始化，从而提升计算效率。<br>3. 禁用时（默认可能为`0`），则保持操作数在循环内的原始处理方式，不进行此类提升优化。<br>该优化特别适用于包含大量重复点积运算的循环场景（如Transformer模型的注意力计算、特征交互等），能有效减少内存带宽压力和计算延迟。但优化效果可能因循环结构复杂度、操作数复用频率等因素而异，部分场景下可能需要通过测试验证是否启用更优。通常情况下，该变量仅在需要针对性优化循环内点积操作的场景中显式设置，以适配特定模型的计算模式。|1|
|MACA_PATH|`MACA_PATH`环境变量主要用于**指定MACA相关组件或库的路径**。MACA通常与SGLang底层的内存管理、计算优化或硬件适配等功能相关（可能是特定的优化模块、运行时库或配置文件集合）。`MACA_PATH`的具体作用是：<br>1. 告诉SGLang系统或其依赖的组件，去哪里查找MACA相关的可执行文件、库文件、配置脚本或其他资源。<br>2. 确保容器环境中运行的SGLang程序能正确定位并加载MACA组件，保证相关优化功能（如内存分配优化、计算调度优化等）正常生效。<br>在容器化部署中，由于文件系统结构相对固定且隔离，显式设置`MACA_PATH`可以避免因路径查找问题导致的MACA组件加载失败，确保依赖MACA的功能模块正常工作。如果该路径配置错误或未设置，可能会导致相关优化功能失效，甚至程序启动失败。||
|LD_LIBRARY_PATH|`LD_LIBRARY_PATH`是一个标准的Linux环境变量，主要用于**指定动态链接库（.so文件）的搜索路径**，其作用在SGLang容器环境中具体体现为：<br>1. **动态链接库的查找与加载**：当SGLang程序或其依赖的组件（如Triton编译器、CUDA库、NVSHMEM等）运行时，需要加载各类动态链接库。`LD_LIBRARY_PATH`会告诉系统在默认路径之外，额外到哪些目录中查找这些库文件。<br>2. **容器环境的路径适配**：容器内部的文件系统结构与宿主机隔离，且库文件的安装路径可能与默认系统路径不同（例如SGLang依赖的特定版本CUDA库、自定义优化库等）。通过设置`LD_LIBRARY_PATH`，可以显式指定容器内这些库的实际存放路径，确保程序能正确找到并加载它们。<br>3. **依赖版本管理**：若容器中存在多个版本的同名库（如不同版本的CUDA驱动库），`LD_LIBRARY_PATH`可以优先指定SGLang所需的特定版本库路径，避免因版本不匹配导致的运行错误。<br>例如，在SGLang容器中可能会设置类似：  `export LD_LIBRARY_PATH=/opt/sglang/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH`以确保程序优先加载SGLang自带的库和指定版本的CUDA库。<br>若该变量配置不当，可能导致“找不到库文件”（如`error while loading shared libraries: libxxx.so`）等错误，进而使SGLang程序无法启动或运行异常。||
|PATH|`PATH`是一个标准的系统环境变量，主要用于**指定可执行程序的搜索路径**，其具体作用如下：<br>1. **定位可执行文件**：当在容器的命令行或脚本中输入一个命令（如`sglang-run`、`triton`等）时，系统会按照`PATH`中定义的目录顺序依次查找对应的可执行文件，找到后便执行该文件。<br>2. **容器环境的命令调用适配**：容器内部的软件（包括SGLang及其依赖工具）通常安装在自定义路径（如`/opt/sglang/bin`、`/usr/local/bin`等）。`PATH`会包含这些路径，确保用户或程序无需输入完整路径就能直接调用SGLang相关命令（如启动服务、运行推理脚本等）。<br>3. **依赖工具的调用保障**：SGLang运行可能依赖的其他工具（如CUDA工具链、日志工具、配置脚本等），`PATH`会包含这些工具的安装目录，确保SGLang在运行过程中能自动找到并调用它们。<br>例如，SGLang容器中可能会设置类似：<br>`export PATH=/opt/sglang/bin:/usr/local/cuda/bin:$PATH`<br>这样用户在容器内直接输入`sglang-server`即可启动服务，无需手动指定`/opt/sglang/bin/sglang-server`的完整路径。<br>若`PATH`配置不当，可能导致输入命令时出现“command not found”错误，无法正常调用SGLang及其依赖的工具。||
|RUSTUP_DIST_SERVER|`RUSTUP_DIST_SERVER`环境变量主要与**Rust工具链的安装和更新**相关，其作用是指定Rustup（Rust工具链的安装管理器）下载相关组件（如编译器、标准库等）时使用的分发服务器地址。具体来说：<br>1. Rustup默认从官方服务器（`https://static.rust-lang.org`）下载Rust工具链的分发文件。<br>2. 当设置`RUSTUP_DIST_SERVER`时，可将其指向自定义的镜像服务器或内部私有服务器（例如国内镜像源、企业内部仓库等），从而优化下载速度或适配特定网络环境（如受限网络、内网部署等）。<br>在SGLang容器环境中，若容器构建或运行过程中需要安装、更新Rust工具链（例如SGLang包含Rust编写的组件，或依赖Rust编译的库），设置该变量可以：<br>1. 加速Rust相关组件的下载，避免官方服务器的网络延迟或访问限制。<br>2. 确保在网络隔离环境中能正常获取Rust工具链资源，保障容器构建或运行的稳定性。<br>该变量仅影响Rustup的资源获取路径，不直接参与SGLang的运行逻辑，主要用于容器环境中Rust工具链的管理和适配。||
|RUSTUP_UPDATE_ROOT|`RUSTUP_UPDATE_ROOT`环境变量与`RUSTUP_DIST_SERVER`类似，均用于控制Rust工具链管理器（Rustup）的资源获取，但具体作用有所不同：<br>该变量用于指定Rustup自身更新所需的资源根路径。Rustup作为工具链管理器，自身也会不定期更新，而`RUSTUP_UPDATE_ROOT`定义了获取这些更新文件（如Rustup的升级程序、版本信息等）的基础URL。具体来说：<br>1. 默认情况下，Rustup从官方地址（`https://static.rust-lang.org/rustup`）获取自身更新资源。<br>2. 当设置`RUSTUP_UPDATE_ROOT`时，可以将其指向自定义的镜像服务器或私有仓库（如国内镜像源、企业内网服务器），从而优化Rustup自身更新的下载速度，或适配网络受限环境。<br>在SGLang容器环境中，若需要更新Rustup本身（例如为了支持新的Rust工具链版本），设置该变量可以：<br>1. 免因官方服务器访问缓慢或受限导致的更新失败。<br>2. 确保在隔离网络环境中能正常完成Rustup的自我更新，保障后续Rust工具链的管理能力。<br>与`RUSTUP_DIST_SERVER`类似，该变量主要用于容器环境中Rust工具链的管理适配，不直接影响SGLang的运行逻辑，仅在需要更新Rustup时生效。||
|PYTHONPATH|`PYTHONPATH`是Python解释器使用的重要环境变量，主要作用是**指定Python模块的搜索路径**，具体体现在以下方面：<br>1. **自定义模块的导入**：SGLang可能包含大量自定义Python模块（如推理逻辑、模型接口、工具函数等），这些模块通常存放在容器内的特定目录（而非Python默认的标准库路径）。`PYTHONPATH`会将这些目录添加到Python的模块搜索路径中，确保程序能通过`import`语句正确导入这些自定义模块。<br>2. **依赖库的路径适配**：容器中可能安装了SGLang专属的Python依赖库（如特定版本的深度学习框架、优化工具等），这些库的安装路径可能不在Python默认搜索范围内。通过`PYTHONPATH`指定这些路径，可以优先加载容器内适配SGLang的依赖版本，避免与系统默认版本冲突。<br>3. **项目结构的灵活性**：SGLang的代码可能按模块化结构组织（如`src/`、`utils/`等目录），`PYTHONPATH`可以将项目根目录添加到搜索路径中，使得不同目录下的模块能相互引用，简化代码组织。<br>若`PYTHONPATH`配置不当，可能导致Python程序出现`ModuleNotFoundError`（找不到模块），进而使SGLang的Python相关功能（如推理脚本、API服务等）无法正常运行。||
|ETCD_ENDPOINTS|`ETCD_ENDPOINTS`环境变量主要用于**指定etcd服务的访问端点**，其作用与分布式系统中的服务发现、配置管理相关。具体来说：<br>1. etcd是一个分布式键值存储系统，常用于服务注册与发现、配置共享、分布式锁等场景。在SGLang的分布式部署模式中（如多节点推理集群、分布式模型服务），可能依赖etcd实现节点间的协调、配置同步或服务状态管理。<br>2. `ETCD_ENDPOINTS`用于定义etcd集群的访问地址列表（通常格式为`http://ip:port,http://ip:port`），告诉SGLang系统如何连接到etcd服务。<br>在实际场景中，该变量的作用包括：<br>1. 使SGLang的各节点（如推理节点、调度节点）能找到并连接到etcd服务，实现集群成员间的信息交换。<br>2. 支持从etcd中获取全局配置（如集群拓扑、资源分配策略等），确保分布式环境中配置的一致性。<br>3. 用于服务注册，让SGLang的各组件能通过etcd发现其他服务实例（如负载均衡、请求路由等场景）。<br>若未正确配置`ETCD_ENDPOINTS`，SGLang的分布式功能可能无法正常工作，例如节点无法加入集群、配置同步失败或服务发现异常等。该变量通常仅在SGLang采用分布式部署架构时需要设置，单机环境下可能无需配置。||
|NATS_SERVER|`NATS_SERVER`环境变量主要用于**指定NATS消息服务器的连接地址**，其作用与分布式系统中的消息通信相关。具体来说：<br>1. NATS是一个轻量级、高性能的分布式消息系统，支持发布/订阅、请求/回复等消息模式，常用于构建松耦合的分布式服务架构。<br>2. 在SGLang的分布式部署场景中（如多节点推理集群、任务调度系统等），可能依赖NATS实现不同组件间的异步通信（例如推理任务的分发、节点状态的上报、结果的回传等）。<br>`NATS_SERVER`环境变量的具体作用是：<br>1. 告知SGLang的各组件（如推理节点、调度器、前端服务等）如何连接到NATS服务器，通常格式为`nats://host:port`（如`nats://nats-service:4222`）。<br>2. 确保分布式环境中所有SGLang相关组件使用统一的消息服务器地址，实现高效的跨节点通信和协同工作。<br>3. 支持通过NATS实现动态的消息路由，适应集群节点的扩缩容或故障转移场景。<br>若该变量配置不当，SGLang的分布式组件可能无法建立消息连接，导致任务调度失败、节点间通信中断等问题。该变量通常在SGLang采用分布式架构且依赖NATS作为消息中间件时需要设置，单机部署场景下可能无需配置。||
|DYN_LOG|`DYN_LOG`环境变量主要用于**控制动态日志（Dynamic Logging）的配置**，其核心作用是灵活调整日志的输出级别、范围或目标，而无需重启正在运行的SGLang服务。具体来说，其功能体现在以下方面：<br>1. **动态调整日志级别**：通过设置`DYN_LOG`，可以在SGLang运行时临时改变日志的详细程度（如从`INFO`级别调整为`DEBUG`以排查问题，或降低到`WARN`以减少日志量），无需重新启动服务。<br>2. **指定日志输出范围**：可以针对性地控制特定模块、组件或代码路径的日志输出（例如仅开启推理引擎相关的日志，或屏蔽某个非关键模块的日志），帮助聚焦于需要关注的系统部分。<br>3. **适配不同运行场景**：在容器化部署中，可根据运行阶段（如调试阶段、生产阶段）通过该变量快速切换日志策略，平衡调试需求与性能开销（详细日志可能影响系统性能）。<br>该变量使得SGLang在容器环境中具备更灵活的日志管理能力，尤其适合动态调试或需要按需调整日志输出的场景，帮助开发者或运维人员更高效地监控和排查问题。|info、debug、error|
|PYTORCH_ENABLE_PG_HIGH_PRIORITY_STREAM|`PYTORCH_ENABLE_PG_HIGH_PRIORITY_STREAM`环境变量主要与**PyTorch的进程组（Process Group）通信性能优化**相关，具体作用如下：<br>该变量用于控制是否为PyTorch进程组的通信操作启用**高优先级CUDA流（High Priority CUDA Stream）**。在分布式训练或推理场景中（如SGLang的多GPU并行部署），PyTorch的进程组负责跨设备/跨节点的数据同步和通信（如AllReduce、Broadcast等操作），这些操作通常依赖CUDA流来管理GPU任务的执行顺序。<br>启用该优化（设置为`1`或`true`）时，进程组的通信操作会被分配到高优先级的CUDA流中执行，这可能带来以下好处：<br>1. 减少通信操作的延迟，使其优先于低优先级的计算任务在GPU上执行。<br>2. 避免通信操作被其他GPU任务阻塞，提高分布式通信的响应速度。<br>3. 优化多GPU间的数据同步效率，尤其在通信密集型的并行场景中（如张量并行、数据并行）。<br>默认情况下，该变量可能未设置或为`0`（不启用），通信操作会使用默认优先级的CUDA流。在SGLang的多GPU部署中，若分布式通信成为性能瓶颈，启用该变量可能有助于提升整体并行效率，但效果可能因硬件架构、并行策略和任务特性而异。<br>该变量仅影响PyTorch进程组的通信行为，间接作用于SGLang依赖的分布式计算模块，通常在需要针对性优化多GPU通信性能时显式设置。|1|
|MACA_DIRECT_DISPATCH|`MACA_DIRECT_DISPATCH`环境变量主要与**MACA组件的计算任务调度模式**相关，其作用是控制是否启用“直接调度”（Direct Dispatch）模式来执行底层计算任务。具体来说：<br>1. MACA通常涉及SGLang底层的计算优化、内存管理或硬件资源调度，而“直接调度”模式可能指绕过某些中间层或通用调度逻辑，直接将计算任务分发到目标硬件单元（如GPU的计算核心）的执行方式。<br>2. 当该变量设置为`1`或`true`时，启用直接调度模式，可能减少任务调度的中间开销，让计算指令更直接地映射到硬件执行，从而提升特定场景下的计算效率。<br>3. 禁用时（默认可能为`0`），则使用常规调度路径，通过更通用的逻辑管理任务分发，可能兼容性更好，但会引入少量调度开销。<br>这一配置通常针对对延迟敏感的计算场景（如小批量推理、高频次的张量运算等），旨在通过简化调度流程来减少任务启动延迟。但直接调度可能对硬件特性或任务类型有更严格的适配要求，因此在某些复杂计算模式下可能需要禁用以保证稳定性。<br>该变量主要影响MACA相关优化的底层执行路径，间接作用于SGLang的推理性能，通常在需要极致优化特定计算任务响应速度时显式设置。|1|
|MACA_GRAPH_LAUNCH_QUEUE_POLICY|`MACA_GRAPH_LAUNCH_QUEUE_POLICY`环境变量主要与**MACA组件中计算图（Graph）的启动队列策略**相关，用于控制计算图任务在调度和执行过程中的队列管理方式。具体作用如下：<br>1. MACA组件可能涉及对复杂计算图（如深度学习模型的计算流程）的优化和执行调度，而计算图的启动通常需要通过队列来管理任务的顺序和优先级。<br>2. 该环境变量用于指定队列的调度策略，例如：  <br>2.1 任务的优先级排序规则（如FIFO先进先出、按优先级权重排序等）；  <br>2.2 队列满时的处理策略（如阻塞等待、丢弃低优先级任务、动态扩容等）；  <br>2.3 多队列间的负载均衡策略（如任务分发的均衡算法）。<br>在SGLang的推理场景中，合理的队列策略能优化计算图任务的执行效率，例如：<br>1. 确保高优先级的推理请求优先执行；<br>2. 避免队列拥堵导致的任务延迟；<br>3. 平衡多GPU或多计算单元间的任务分配。<br>该变量的取值通常为特定的策略标识（如字符串或枚举值），具体可选值取决于MACA组件的实现。配置时需根据实际负载特征（如请求量、任务优先级差异）选择合适的策略，以兼顾吞吐量和响应速度。<br>此变量主要影响计算图任务的调度逻辑，间接作用于SGLang的推理性能和资源利用率，通常在需要针对性优化任务队列管理时显式设置。|3|
|MCDBG_GRAPH_LAUNCH_QUEUE_POLICY|`MCDBG_GRAPH_LAUNCH_QUEUE_POLICY`环境变量主要与**MCDBG组件（可能是调试或监控相关的模块）中计算图启动队列的管理策略**相关，其作用是控制计算图任务在调试或监控场景下的队列调度行为。具体来说：<br>1. MCDBG可能是SGLang中负责计算图调试、性能监控或任务跟踪的组件，而`GRAPH_LAUNCH_QUEUE_POLICY`明确指向计算图启动阶段的队列管理规则。<br>2. 该变量用于指定在调试或监控模式下，计算图任务进入执行队列后的调度策略，可能包括：  <br>2.1 任务的排序方式（如按提交顺序、优先级、调试标记等）；  <br>2.2 队列满时的处理机制（如暂停等待、记录调试日志后丢弃、触发告警等）；  <br>2.3 与调试工具的协同策略（如优先执行带调试标记的任务、为调试任务预留队列空间等）。<br>在实际场景中，该变量的作用体现在：<br>1. 确保调试过程中能精准控制计算图任务的执行顺序，方便定位问题；<br>2. 在监控模式下，通过合理的队列策略保证性能数据采集的完整性（如避免高优先级任务淹没监控数据）；<br>3. 平衡调试需求与正常任务执行，避免调试操作过度占用队列资源导致业务延迟。<br>其配置值通常为特定的策略标识符（如字符串或枚举值），具体取决于MCDBG组件的实现。该变量主要用于调试或监控场景，对SGLang的常规运行影响较小，通常在需要精细化控制调试过程中的任务队列时显式设置。|3|
|FUSED_RMSNORM_QUANT|`FUSED_RMSNORM_QUANT`环境变量主要与**融合RMS归一化（RMSNorm）操作的量化优化**相关，具体作用如下：<br>1. **RMSNorm**是深度学习中常用的归一化操作（类似LayerNorm，但计算方式更简洁），广泛应用于Transformer等模型中，用于稳定训练和推理过程。<br>2. **量化**则是将模型参数或计算过程从高精度（如FP32）转换为低精度（如INT8、FP16）的技术，旨在减少内存占用和计算开销，提升推理速度。<br>`FUSED_RMSNORM_QUANT`的核心作用是控制是否启用**融合的RMSNorm量化优化**：<br>1. **融合（Fused）**：指将RMSNorm操作与后续的量化步骤合并为一个整体计算单元，减少中间数据的读写和转换开销，提升计算效率。<br>2. **量化优化**：针对RMSNorm操作的特性（如数值范围、计算模式）设计专门的量化策略，在保证精度损失可接受的前提下，最大化量化带来的性能收益。<br>当该变量设置为`1`或`true`时，启用这项优化，可能在包含大量RMSNorm操作的模型（如LLaMA、GPT等大语言模型）推理中显著提升效率；默认可能为`0`（不启用）。<br>该变量主要用于针对性优化大语言模型中常见的RMSNorm+量化组合场景，尤其适合对推理性能要求较高的部署环境，其效果可能因模型结构和量化策略而异。|False|
|TORCHDYNAMO_DISABLE|`TORCHDYNAMO_DISABLE`环境变量主要用于**控制是否禁用PyTorch的TorchDynamo组件**，其作用与PyTorch的动态图编译优化相关。具体来说：<br>1. TorchDynamo是PyTorch中的动态图优化工具，能够实时捕获Python字节码并将其转换为更高效的计算图表示（如TorchScript、ONNX或针对特定硬件的优化代码），从而提升模型的执行效率，尤其适用于动态控制流较多的场景。<br>2. 在SGLang中，若其底层依赖PyTorch进行模型推理或计算，可能会默认启用TorchDynamo来优化计算过程。<br>`TORCHDYNAMO_DISABLE`的作用是：<br>1. 当设置为`1`或`true`时，会强制禁用TorchDynamo的优化功能，使PyTorch回到传统的解释执行模式，不进行动态图编译优化。<br>2. 禁用的常见场景包括：排查因TorchDynamo优化导致的兼容性问题（如计算结果异常、推理逻辑错误）；对比优化前后的性能差异以定位瓶颈；适配某些暂不支持TorchDynamo的自定义算子或模型结构。<br>默认情况下，该变量可能未设置或为`0`（启用TorchDynamo），以利用其优化提升SGLang的PyTorch相关计算性能。仅在遇到与TorchDynamo相关的问题时，才需要显式设置该变量禁用优化。<br>该变量主要影响PyTorch层面的动态编译行为，间接作用于SGLang中依赖PyTorch的推理或计算模块。|1|
||||