# 环境变量释义

|变量名称|释义|示例|
|----|------------------|----|
|SGLANG_EXPERT_DISTRIBUTION_RECORD_DIR|在SGLang的容器环境中,`SGLANG_EXPERT_DISTRIBUTION_RECORD_DIR`环境变量主要用于指定**专家模型分布记录的存储目录**。<br>具体来说，它的作用包括：<br>1. 当使用SGLang的专家模型分布（expert distribution）功能时（例如在MoE架构或分布式推理场景中），该变量定义了记录专家分配、负载均衡或路由信息的文件存储路径。<br>2. 这些记录文件可用于调试分布式推理过程中的专家选择策略、性能分析或问题排查。<br>3. 若未指定该变量，SGLang可能会使用默认目录（通常是临时目录或当前工作目录）来存储这些记录文件。<br>通过设置该环境变量，用户可以灵活指定记录文件的存储位置，方便后续对分布式推理过程进行分析和优化。||
|GLOO_SOCKET_IFNAME|在SGLang的容器环境中，`GLOO_SOCKET_IFNAME`环境变量主要用于指定**GLOO通信库使用的网络接口名称**。<br>GLOO是Facebook开发的一个分布式通信库，常被用于深度学习框架（如PyTorch）和分布式计算场景中，负责节点间的数据传输和通信协调。在SGLang的分布式部署场景（如多节点推理、MoE架构的专家节点通信等）中，可能会依赖GLOO实现跨容器/跨节点的通信。<br>该环境变量的具体作用是：<br>1. 明确指定容器内用于GLOO通信的网络接口（如`eth0`、`enp0s3`等）<br>2. 避免在多网络接口的容器环境中，GLOO错误选择不合适的网络接口（如内网接口、管理接口等）<br>3. 优化分布式通信性能，确保使用预期的高性能网络链路。<br>如果不设置该变量，GLOO可能会自动选择一个网络接口，但在复杂网络环境（如容器多网卡、overlay网络等）中可能导致通信失败或性能下降。因此，在SGLang的分布式部署中，通常需要根据容器网络配置显式指定该变量。|bond0|
|MACA_SMALL_PAGESIZE_ENABLE|在SGLang的容器环境中，`MACA_SMALL_PAGESIZE_ENABLE`环境变量主要与**内存分配和页面管理优化**相关，具体作用如下：<br>该变量通常用于控制是否启用"小页面"（small page）内存分配模式。在高性能计算或大模型推理场景中，内存管理的效率对整体性能影响显著：<br>1. 当启用（设置为`1`或`true`）时，系统可能会使用更小的内存页面粒度进行分配，这有助于减少内存碎片，提高内存利用率，尤其适合处理大量小内存块的场景。<br>2. 当禁用（默认可能为`0`或`false`）时，可能使用默认的页面大小（通常较大，如4KB或更大），这在某些大内存连续分配场景中可能更高效。<br>这一配置通常与SGLang底层依赖的内存管理库（如MACA相关组件）配合工作，旨在根据具体 workload 特性优化内存使用效率，进而提升模型推理或计算性能。在容器环境中显式设置该变量，可以更精确地控制内存行为，适配不同的硬件资源和应用需求。|1|
|NVSHMEM_DISABLE_CUDA_VMM|在SGLang的容器环境中，`NVSHMEM_DISABLE_CUDA_VMM`环境变量与**NVIDIA SHMEM（NVSHMEM）库的CUDA虚拟内存管理（VMM）功能**相关，其主要作用是控制是否禁用CUDA VMM功能。<br>具体来说：<br>1. NVSHMEM是NVIDIA提供的分布式内存编程库，用于跨GPU或跨节点的高性能通信，在SGLang的多GPU分布式推理场景中可能被用于高效数据交换。<br>2. CUDA VMM（虚拟内存管理）是CUDA的一项功能，允许应用程序使用更大的虚拟地址空间，灵活管理GPU内存。<br>3. 当`NVSHMEM_DISABLE_CUDA_VMM`设置为`1`或`true`时，会禁用NVSHMEM对CUDA VMM的使用；默认情况下可能为`0`（启用状态）。<br>在实际场景中，禁用该功能可能是为了：<br>1. 解决特定环境下CUDA VMM与NVSHMEM兼容问题（如驱动版本不匹配、硬件限制等）。<br>2. 规避某些边缘场景下的内存管理性能问题或bug。<br>3. 适配需要使用传统内存管理模式的部署环境。<br>该变量通常仅在遇到NVSHMEM与CUDA VMM相关的兼容性问题时才需要显式设置，一般情况下保持默认值即可。|1|
|NVSHMEM_SYMMETRIC_SIZE|在SGLang的容器环境中，`NVSHMEM_SYMMETRIC_SIZE`环境变量用于配置**NVIDIA SHMEM（NVSHMEM）库的对称内存区域大小**。<br>具体作用如下：<br>1. NVSHMEM是NVIDIA针对GPU间通信设计的分布式内存库，其核心概念之一是"对称内存区域"（symmetric memory region）——这是一块在所有参与通信的GPU上具有相同地址和大小的内存区域，便于跨设备直接访问数据。<br>2. `NVSHMEM_SYMMETRIC_SIZE`用于指定该对称内存区域的总大小（通常以字节为单位），所有参与通信的GPU会分配相同大小的对称内存。<br>3. 在SGLang的多GPU分布式推理场景中（如MoE架构的专家并行、张量并行等），对称内存区域用于高效交换中间计算结果、模型参数分片等数据，减少跨GPU通信的开销。<br>若未显式设置，NVSHMEM可能会使用默认大小（通常取决于系统配置），但在大模型场景下，可能需要根据模型规模、通信需求手动调整该值，以避免内存不足或资源浪费。设置时需确保所有节点的配置一致，否则可能导致通信异常。|3g|
|TRITON_DISABLE_MACA_OPT_MMA_PREFETCH|在SGLang的容器环境中，`TRITON_DISABLE_MACA_OPT_MMA_PREFETCH`环境变量主要与**Triton编译器的MACA优化相关**，具体作用是控制是否禁用MACA（可能是指特定的内存访问或计算优化组件）中的MMA（矩阵乘法累加）预取优化。具体来说：<br>1. Triton是用于GPU编程的开源编译器，常用于优化深度学习中的张量运算（如矩阵乘法），在SGLang的模型推理过程中可能被用于加速底层计算。<br>2. MMA（Matrix Multiply-Accumulate）是GPU架构中用于高效执行矩阵乘法的核心指令，预取优化（prefetch）则是通过提前加载数据到缓存来减少内存访问延迟的技术。<br>3. 当该环境变量设置为`1`或`true`时，会禁用Triton编译器针对MMA操作的预取优化；默认情况下可能为`0`（启用状态）。<br>在实际场景中，禁用该优化可能是为了：<br>1. 解决特定硬件或软件版本下，预取优化导致的兼容性问题（如计算结果异常、程序崩溃等）。<br>2. 针对某些模型或计算场景，预取策略可能反而引入额外开销，此时禁用可提升性能。<br>3. 调试底层计算优化相关的问题，定位性能瓶颈或逻辑错误。<br>该变量通常仅在遇到与Triton编译器优化相关的问题时才需要显式设置，一般情况下保持默认值（启用优化）即可获得更好的计算效率。|1|